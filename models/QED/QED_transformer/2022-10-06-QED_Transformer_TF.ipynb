{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6n5JafNiO5rn"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# os.system(\"export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$CONDA_PREFIX/lib/\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install icecream"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGRbjk7wPAsz",
        "outputId": "d7e3f5f5-b614-429e-a667-50c571cc635c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting icecream\n",
            "  Downloading icecream-2.1.3-py2.py3-none-any.whl (8.4 kB)\n",
            "Collecting executing>=0.3.1\n",
            "  Downloading executing-1.1.0-py2.py3-none-any.whl (22 kB)\n",
            "Collecting colorama>=0.3.9\n",
            "  Downloading colorama-0.4.5-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: pygments>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from icecream) (2.6.1)\n",
            "Collecting asttokens>=2.0.1\n",
            "  Downloading asttokens-2.0.8-py2.py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from asttokens>=2.0.1->icecream) (1.15.0)\n",
            "Installing collected packages: executing, colorama, asttokens, icecream\n",
            "Successfully installed asttokens-2.0.8 colorama-0.4.5 executing-1.1.0 icecream-2.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "C06NN7uQO5ro"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import os\n",
        "from icecream import ic \n",
        "import csv\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pathlib\n",
        "import random\n",
        "import string\n",
        "import re\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7n73nR-O5rp",
        "outputId": "1b7727de-c308-49e7-d13e-fe4df6e7e7da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ],
      "source": [
        "print(tf.config.list_physical_devices('GPU'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# only needed for colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rsilc8q6PSD3",
        "outputId": "c6b08027-286c-45be-d61c-944e262c73a0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/SYMBA/')"
      ],
      "metadata": {
        "id": "JqMD3p1lPZNt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1SXI2JCO5rp",
        "outputId": "58903851-6334-48b2-b7eb-1d18fceca895"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['2022-07-20-RNNAttention',\n",
              " '2022-07-20-FirstTransformer',\n",
              " 'data.nosync_old',\n",
              " 'data.nosync',\n",
              " '2022-08-22-Transformer',\n",
              " 'models',\n",
              " '2022-08-24-Transformer-NewData',\n",
              " 'QED']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "os.listdir()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "FEOTQmQlO5rq"
      },
      "outputs": [],
      "source": [
        "amplitudes_files = [\n",
        "    \"data.nosync/train/QED_amplitudes_TreeLevel_1to2_train.txt\",\n",
        "    \"data.nosync/train/QED_amplitudes_TreeLevel_2to1_train.txt\",\n",
        "    \"data.nosync/train/QED_amplitudes_TreeLevel_2to2_train.txt\",\n",
        "    \"data.nosync/train/QED_amplitudes_TreeLevel_2to3_train.txt\",\n",
        "    \"data.nosync/train/QED_amplitudes_TreeLevel_3to2_train.txt\",\n",
        "]\n",
        "sqamplitudes_files = [\n",
        "    \"data.nosync/train/QED_sqamplitudes_TreeLevel_1to2_simplified_shortened_hybridprefix_train.txt\",\n",
        "    \"data.nosync/train/QED_sqamplitudes_TreeLevel_2to1_simplified_shortened_hybridprefix_train.txt\",\n",
        "    \"data.nosync/train/QED_sqamplitudes_TreeLevel_2to2_simplified_shortened_hybridprefix_train.txt\",\n",
        "    \"data.nosync/train/QED_sqamplitudes_TreeLevel_2to3_simplified_shortened_hybridprefix_train.txt\",\n",
        "    \"data.nosync/train/QED_sqamplitudes_TreeLevel_3to2_simplified_shortened_hybridprefix_train.txt\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "6fZoGO0TO5rq"
      },
      "outputs": [],
      "source": [
        "X_train = []\n",
        "for file in amplitudes_files:\n",
        "    with open(file, 'r') as f:\n",
        "        for line in f.readlines() :\n",
        "            line = line.split(\",\")\n",
        "            line[-1] = line[-1].replace(\"\\n\", \"\")\n",
        "            X_train.append(line)\n",
        "\n",
        "y_train = []\n",
        "for file in sqamplitudes_files:\n",
        "    with open(file, 'r') as f:\n",
        "        for line in f.readlines() :\n",
        "            line = line.split(\",\")\n",
        "            line[-1] = line[-1].replace(\"\\n\", \"\")\n",
        "            # line = [\"[START]\"] + line + [\"[END]\"]\n",
        "            y_train.append(line)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_26MHqKoO5rq"
      },
      "outputs": [],
      "source": [
        "assert len(X_train) == len(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "XsI5v58HO5rq"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.02, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BaRxwcXO5rr",
        "outputId": "7b3e5a8b-1600-4345-f3b7-3f4aaa9d266b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ic| Error: Failed to access the underlying source code for analysis. Was ic() invoked in a REPL (e.g. from the command line), a frozen application (e.g. packaged with PyInstaller), or did the underlying source code change during execution?\n",
            "ic| Error: Failed to access the underlying source code for analysis. Was ic() invoked in a REPL (e.g. from the command line), a frozen application (e.g. packaged with PyInstaller), or did the underlying source code change during execution?\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4770"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "ic(len(X_train))\n",
        "ic(len(X_val))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2fsRt6vO5rr"
      },
      "source": [
        "# Creating the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "yHawkzHMO5rs"
      },
      "outputs": [],
      "source": [
        "vocab_size = 500\n",
        "sequence_length = 350\n",
        "batch_size = 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jo3BE6jtO5rs",
        "outputId": "d4a5698e-d4c0-4a02-c600-c47f785f173e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X train: 0.9461537474167918% okay\n",
            "y train: 0.8247140821749008% okay\n",
            "X val: 0.9410901467505242% okay\n",
            "y val: 0.8169811320754717% okay\n"
          ]
        }
      ],
      "source": [
        "X_train_idx_okay = np.where([len(x) < sequence_length for x in X_train])[0]\n",
        "y_train_idx_okay = np.where([len(y) < sequence_length for y in y_train])[0]\n",
        "train_idx_okay = np.intersect1d(X_train_idx_okay, y_train_idx_okay) \n",
        "X_train_short = [X_train[i] for i in train_idx_okay]\n",
        "y_train_short = [y_train[i] for i in train_idx_okay]\n",
        "X_train_text = [\" \".join(x) for x in X_train_short]\n",
        "y_train_text = [\" \".join(yy) for yy in y_train_short]\n",
        "\n",
        "print(\"X train: {}% okay\".format(len(X_train_idx_okay)/len(X_train)))\n",
        "print(\"y train: {}% okay\".format(len(y_train_idx_okay)/len(X_train)))\n",
        "\n",
        "\n",
        "X_val_idx_okay = np.where([len(x) < sequence_length for x in X_val])[0]\n",
        "y_val_idx_okay = np.where([len(y) < sequence_length for y in y_val])[0]\n",
        "val_idx_okay = np.intersect1d(X_val_idx_okay, y_val_idx_okay) \n",
        "X_val_short = [X_val[i] for i in val_idx_okay]\n",
        "y_val_short = [y_val[i] for i in val_idx_okay]\n",
        "X_val_text = [\" \".join(x) for x in X_val_short]\n",
        "y_val_text = [\" \".join(yy) for yy in y_val_short]\n",
        "\n",
        "print(\"X val: {}% okay\".format(len(X_val_idx_okay)/len(X_val)))\n",
        "print(\"y val: {}% okay\".format(len(y_val_idx_okay)/len(X_val)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "l0kbsAZuO5rt"
      },
      "outputs": [],
      "source": [
        "def custom_standardization(input_string):\n",
        "    return input_string\n",
        "\n",
        "X_vectorization = TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length,\n",
        "    standardize=None,\n",
        ")\n",
        "\n",
        "y_vectorization = TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length+1,\n",
        "    standardize=None,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "eJc5yj8bO5rt"
      },
      "outputs": [],
      "source": [
        "X_vectorization.adapt(X_train_text)\n",
        "y_vectorization.adapt(y_train_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "jgmuozLCO5rt"
      },
      "outputs": [],
      "source": [
        "def format_dataset(X, y):\n",
        "    X_vec = X_vectorization(X)\n",
        "    y_vec = y_vectorization(y)\n",
        "    return (\n",
        "        {\n",
        "            \"encoder_inputs\": X_vec,\n",
        "            \"decoder_inputs\": y_vec[:, :-1],\n",
        "        },\n",
        "        y_vec[:, 1:],\n",
        "    )\n",
        "\n",
        "\n",
        "def make_dataset(X_text, y_text):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((X_text, y_text))\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.map(format_dataset)\n",
        "    return dataset.shuffle(2048).prefetch(16).cache()\n",
        "\n",
        "\n",
        "train_ds = make_dataset(X_train_text, y_train_text)\n",
        "val_ds = make_dataset(X_val_text, y_val_text)\n",
        "# test_ds = make_dataset(X_test_text, y_test_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7f7hT8K3O5ru"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "CwszbHP8O5ru"
      },
      "outputs": [],
      "source": [
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super(TransformerEncoder, self).__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(dense_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        if mask is not None:\n",
        "            padding_mask = tf.cast(mask[:, tf.newaxis, tf.newaxis, :], dtype=\"int32\")\n",
        "        attention_output = self.attention(\n",
        "            query=inputs, value=inputs, key=inputs, attention_mask=padding_mask\n",
        "        )\n",
        "        proj_input = self.layernorm_1(inputs + attention_output)\n",
        "        proj_output = self.dense_proj(proj_input)\n",
        "        return self.layernorm_2(proj_input + proj_output)\n",
        "\n",
        "\n",
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n",
        "        super(PositionalEmbedding, self).__init__(**kwargs)\n",
        "        self.token_embeddings = layers.Embedding(\n",
        "            input_dim=vocab_size, output_dim=embed_dim\n",
        "        )\n",
        "        self.position_embeddings = layers.Embedding(\n",
        "            input_dim=sequence_length, output_dim=embed_dim\n",
        "        )\n",
        "        self.sequence_length = sequence_length\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "    def call(self, inputs):\n",
        "        length = tf.shape(inputs)[-1]\n",
        "        positions = tf.range(start=0, limit=length, delta=1)\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "        return embedded_tokens + embedded_positions\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return tf.math.not_equal(inputs, 0)\n",
        "\n",
        "\n",
        "class TransformerDecoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, latent_dim, num_heads, **kwargs):\n",
        "        super(TransformerDecoder, self).__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.latent_dim = latent_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention_1 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.attention_2 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(latent_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.layernorm_3 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs, encoder_outputs, mask=None):\n",
        "        causal_mask = self.get_causal_attention_mask(inputs)\n",
        "        if mask is not None:\n",
        "            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype=\"int32\")\n",
        "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
        "\n",
        "        attention_output_1 = self.attention_1(\n",
        "            query=inputs, value=inputs, key=inputs, attention_mask=causal_mask\n",
        "        )\n",
        "        out_1 = self.layernorm_1(inputs + attention_output_1)\n",
        "\n",
        "        attention_output_2 = self.attention_2(\n",
        "            query=out_1,\n",
        "            value=encoder_outputs,\n",
        "            key=encoder_outputs,\n",
        "            attention_mask=padding_mask,\n",
        "        )\n",
        "        out_2 = self.layernorm_2(out_1 + attention_output_2)\n",
        "\n",
        "        proj_output = self.dense_proj(out_2)\n",
        "        return self.layernorm_3(out_2 + proj_output)\n",
        "\n",
        "    def get_causal_attention_mask(self, inputs):\n",
        "        input_shape = tf.shape(inputs)\n",
        "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
        "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
        "        j = tf.range(sequence_length)\n",
        "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
        "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
        "        mult = tf.concat(\n",
        "            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)],\n",
        "            axis=0,\n",
        "        )\n",
        "        return tf.tile(mask, mult)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5PRaPL-O5rv",
        "outputId": "4d576f15-b0bb-4c3f-bf5f-b01fed4bd3e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " encoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " positional_embedding (Position  (None, None, 256)   217600      ['encoder_inputs[0][0]']         \n",
            " alEmbedding)                                                                                     \n",
            "                                                                                                  \n",
            " decoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " transformer_encoder (Transform  (None, None, 256)   3155456     ['positional_embedding[0][0]']   \n",
            " erEncoder)                                                                                       \n",
            "                                                                                                  \n",
            " model_1 (Functional)           (None, None, 500)    5605620     ['decoder_inputs[0][0]',         \n",
            "                                                                  'transformer_encoder[0][0]']    \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 8,978,676\n",
            "Trainable params: 8,978,676\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "embed_dim = 256  # 512\n",
        "latent_dim = 2048  # 16384\n",
        "num_heads = 8\n",
        "\n",
        "# with tpu_strategy.scope(): # creating the model in the TPUStrategy scope means we will train the model on the TPU\n",
        "encoder_inputs = keras.Input(shape=(None,), dtype=\"int32\", name=\"encoder_inputs\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n",
        "encoder_outputs = TransformerEncoder(embed_dim, latent_dim, num_heads)(x)\n",
        "encoder = keras.Model(encoder_inputs, encoder_outputs)\n",
        "\n",
        "decoder_inputs = keras.Input(shape=(None,), dtype=\"int32\", name=\"decoder_inputs\")\n",
        "encoded_seq_inputs = keras.Input(shape=(None, embed_dim), name=\"decoder_state_inputs\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
        "x = TransformerDecoder(embed_dim, latent_dim, num_heads)(x, encoded_seq_inputs)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
        "decoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\n",
        "\n",
        "decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n",
        "transformer = keras.Model(\n",
        "    [encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\"\n",
        ")\n",
        "transformer.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "_ZK0e6S8O5rv"
      },
      "outputs": [],
      "source": [
        "def create_lr_func(min_lr, max_epochs, max_lr_factor=4.0):\n",
        "    initial_lr = min_lr \n",
        "    max_lr = min_lr*max_lr_factor \n",
        "    def learning_rate_cyclic(epoch):\n",
        "        if epoch <= (max_epochs / 2):\n",
        "            lr = initial_lr + (max_lr-initial_lr) * epoch/(max_epochs/2)\n",
        "            return lr\n",
        "        if (epoch > (max_epochs / 2)) & (epoch < max_epochs):\n",
        "            lr = max_lr - (max_lr-initial_lr) * (epoch-max_epochs/2)/(max_epochs/2)\n",
        "            return lr\n",
        "        else:\n",
        "            lr = initial_lr*np.exp(-(epoch-max_epochs)/10)\n",
        "            return lr\n",
        "    return learning_rate_cyclic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "lazUiOOGO5rv",
        "outputId": "aea28aa0-ad35-4d9f-eb61-b1396ac3461b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'learning rate')"
            ]
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "xrange = range(0,50)\n",
        "yrange = [create_lr_func(0.0005, 20, 4.0)(x) for x in xrange]\n",
        "plt.plot(xrange, yrange)\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"learning rate\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2tQXQA_O5rw",
        "outputId": "95bcde03-5f58-4bc6-ece5-528dea8da049"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " encoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " positional_embedding (Position  (None, None, 256)   217600      ['encoder_inputs[0][0]']         \n",
            " alEmbedding)                                                                                     \n",
            "                                                                                                  \n",
            " decoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " transformer_encoder (Transform  (None, None, 256)   3155456     ['positional_embedding[0][0]']   \n",
            " erEncoder)                                                                                       \n",
            "                                                                                                  \n",
            " model_1 (Functional)           (None, None, 500)    5605620     ['decoder_inputs[0][0]',         \n",
            "                                                                  'transformer_encoder[0][0]']    \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 8,978,676\n",
            "Trainable params: 8,978,676\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/50\n",
            "23403/23403 [==============================] - 464s 19ms/step - loss: 0.1946 - accuracy: 0.8981 - val_loss: 0.0378 - val_accuracy: 0.9805 - lr: 5.0000e-04\n",
            "Epoch 2/50\n",
            "23403/23403 [==============================] - 456s 19ms/step - loss: 0.0351 - accuracy: 0.9822 - val_loss: 0.0174 - val_accuracy: 0.9912 - lr: 6.5000e-04\n",
            "Epoch 3/50\n",
            "23403/23403 [==============================] - 456s 19ms/step - loss: 0.0219 - accuracy: 0.9891 - val_loss: 0.0130 - val_accuracy: 0.9936 - lr: 8.0000e-04\n",
            "Epoch 4/50\n",
            "23403/23403 [==============================] - 454s 19ms/step - loss: 0.0172 - accuracy: 0.9916 - val_loss: 0.0099 - val_accuracy: 0.9950 - lr: 9.5000e-04\n",
            "Epoch 5/50\n",
            "23403/23403 [==============================] - 454s 19ms/step - loss: 0.0149 - accuracy: 0.9927 - val_loss: 0.0113 - val_accuracy: 0.9944 - lr: 0.0011\n",
            "Epoch 6/50\n",
            "23403/23403 [==============================] - 455s 19ms/step - loss: 0.0137 - accuracy: 0.9933 - val_loss: 0.0072 - val_accuracy: 0.9964 - lr: 0.0012\n",
            "Epoch 7/50\n",
            "23403/23403 [==============================] - 454s 19ms/step - loss: 0.0129 - accuracy: 0.9937 - val_loss: 0.0097 - val_accuracy: 0.9953 - lr: 0.0014\n",
            "Epoch 8/50\n",
            "23403/23403 [==============================] - 453s 19ms/step - loss: 0.0123 - accuracy: 0.9940 - val_loss: 0.0082 - val_accuracy: 0.9959 - lr: 0.0016\n",
            "Epoch 9/50\n",
            "23403/23403 [==============================] - 452s 19ms/step - loss: 0.0120 - accuracy: 0.9942 - val_loss: 0.0086 - val_accuracy: 0.9958 - lr: 0.0017\n",
            "Epoch 10/50\n",
            "23403/23403 [==============================] - 452s 19ms/step - loss: 0.0122 - accuracy: 0.9941 - val_loss: 0.0101 - val_accuracy: 0.9951 - lr: 0.0019\n",
            "Epoch 11/50\n",
            "23403/23403 [==============================] - 453s 19ms/step - loss: 0.0135 - accuracy: 0.9934 - val_loss: 0.0118 - val_accuracy: 0.9941 - lr: 0.0020\n",
            "Epoch 12/50\n",
            "23403/23403 [==============================] - 452s 19ms/step - loss: 0.0131 - accuracy: 0.9936 - val_loss: 0.0102 - val_accuracy: 0.9949 - lr: 0.0019\n",
            "Epoch 13/50\n",
            "23403/23403 [==============================] - 452s 19ms/step - loss: 0.0137 - accuracy: 0.9933 - val_loss: 0.0111 - val_accuracy: 0.9945 - lr: 0.0017\n",
            "Epoch 14/50\n",
            "23403/23403 [==============================] - 463s 20ms/step - loss: 0.0129 - accuracy: 0.9937 - val_loss: 0.0105 - val_accuracy: 0.9948 - lr: 0.0016\n",
            "Epoch 15/50\n",
            "23403/23403 [==============================] - 456s 19ms/step - loss: 0.0116 - accuracy: 0.9943 - val_loss: 0.0085 - val_accuracy: 0.9957 - lr: 0.0014\n",
            "Epoch 16/50\n",
            "23403/23403 [==============================] - 458s 20ms/step - loss: 0.0098 - accuracy: 0.9951 - val_loss: 0.0093 - val_accuracy: 0.9954 - lr: 0.0012\n",
            "Epoch 17/50\n",
            "23403/23403 [==============================] - 453s 19ms/step - loss: 0.0080 - accuracy: 0.9960 - val_loss: 0.0061 - val_accuracy: 0.9970 - lr: 0.0011\n",
            "Epoch 18/50\n",
            "23403/23403 [==============================] - 454s 19ms/step - loss: 0.0063 - accuracy: 0.9968 - val_loss: 0.0040 - val_accuracy: 0.9980 - lr: 9.5000e-04\n",
            "Epoch 19/50\n",
            "23403/23403 [==============================] - 462s 20ms/step - loss: 0.0046 - accuracy: 0.9977 - val_loss: 0.0031 - val_accuracy: 0.9984 - lr: 8.0000e-04\n",
            "Epoch 20/50\n",
            "23403/23403 [==============================] - 465s 20ms/step - loss: 0.0034 - accuracy: 0.9982 - val_loss: 0.0025 - val_accuracy: 0.9987 - lr: 6.5000e-04\n",
            "Epoch 21/50\n",
            "23403/23403 [==============================] - 469s 20ms/step - loss: 0.0024 - accuracy: 0.9988 - val_loss: 0.0016 - val_accuracy: 0.9991 - lr: 5.0000e-04\n",
            "Epoch 22/50\n",
            "23403/23403 [==============================] - 462s 20ms/step - loss: 0.0020 - accuracy: 0.9989 - val_loss: 0.0014 - val_accuracy: 0.9992 - lr: 4.5242e-04\n",
            "Epoch 23/50\n",
            "23403/23403 [==============================] - 454s 19ms/step - loss: 0.0017 - accuracy: 0.9991 - val_loss: 0.0013 - val_accuracy: 0.9993 - lr: 4.0937e-04\n",
            "Epoch 24/50\n",
            "23403/23403 [==============================] - 453s 19ms/step - loss: 0.0014 - accuracy: 0.9992 - val_loss: 9.7432e-04 - val_accuracy: 0.9995 - lr: 3.7041e-04\n",
            "Epoch 25/50\n",
            "23403/23403 [==============================] - 454s 19ms/step - loss: 0.0012 - accuracy: 0.9993 - val_loss: 9.1066e-04 - val_accuracy: 0.9995 - lr: 3.3516e-04\n",
            "Epoch 26/50\n",
            "23403/23403 [==============================] - 454s 19ms/step - loss: 0.0010 - accuracy: 0.9994 - val_loss: 7.4041e-04 - val_accuracy: 0.9996 - lr: 3.0327e-04\n",
            "Epoch 27/50\n",
            "23403/23403 [==============================] - 452s 19ms/step - loss: 9.3018e-04 - accuracy: 0.9995 - val_loss: 6.7922e-04 - val_accuracy: 0.9996 - lr: 2.7441e-04\n",
            "Epoch 28/50\n",
            "23403/23403 [==============================] - 450s 19ms/step - loss: 7.9932e-04 - accuracy: 0.9995 - val_loss: 6.3560e-04 - val_accuracy: 0.9996 - lr: 2.4829e-04\n",
            "Epoch 29/50\n",
            "23403/23403 [==============================] - 450s 19ms/step - loss: 6.9405e-04 - accuracy: 0.9996 - val_loss: 6.0903e-04 - val_accuracy: 0.9996 - lr: 2.2466e-04\n",
            "Epoch 30/50\n",
            "23403/23403 [==============================] - 449s 19ms/step - loss: 6.1458e-04 - accuracy: 0.9996 - val_loss: 5.3764e-04 - val_accuracy: 0.9997 - lr: 2.0328e-04\n",
            "Epoch 31/50\n",
            "23403/23403 [==============================] - 449s 19ms/step - loss: 5.5188e-04 - accuracy: 0.9997 - val_loss: 4.8580e-04 - val_accuracy: 0.9997 - lr: 1.8394e-04\n",
            "Epoch 32/50\n",
            "23403/23403 [==============================] - 449s 19ms/step - loss: 4.8313e-04 - accuracy: 0.9997 - val_loss: 5.0047e-04 - val_accuracy: 0.9997 - lr: 1.6644e-04\n",
            "Epoch 33/50\n",
            "23403/23403 [==============================] - 448s 19ms/step - loss: 4.3431e-04 - accuracy: 0.9997 - val_loss: 4.3972e-04 - val_accuracy: 0.9997 - lr: 1.5060e-04\n",
            "Epoch 34/50\n",
            "23403/23403 [==============================] - 447s 19ms/step - loss: 4.0460e-04 - accuracy: 0.9997 - val_loss: 4.0034e-04 - val_accuracy: 0.9997 - lr: 1.3627e-04\n",
            "Epoch 35/50\n",
            "23403/23403 [==============================] - 447s 19ms/step - loss: 3.6304e-04 - accuracy: 0.9998 - val_loss: 4.0493e-04 - val_accuracy: 0.9997 - lr: 1.2330e-04\n",
            "Epoch 36/50\n",
            "23403/23403 [==============================] - 447s 19ms/step - loss: 3.3220e-04 - accuracy: 0.9998 - val_loss: 3.9232e-04 - val_accuracy: 0.9997 - lr: 1.1157e-04\n",
            "Epoch 37/50\n",
            "23403/23403 [==============================] - 447s 19ms/step - loss: 3.1035e-04 - accuracy: 0.9998 - val_loss: 3.7711e-04 - val_accuracy: 0.9997 - lr: 1.0095e-04\n",
            "Epoch 38/50\n",
            "23403/23403 [==============================] - 448s 19ms/step - loss: 2.8875e-04 - accuracy: 0.9998 - val_loss: 3.5007e-04 - val_accuracy: 0.9998 - lr: 9.1342e-05\n",
            "Epoch 39/50\n",
            "23403/23403 [==============================] - 446s 19ms/step - loss: 2.7303e-04 - accuracy: 0.9998 - val_loss: 3.5346e-04 - val_accuracy: 0.9997 - lr: 8.2649e-05\n",
            "Epoch 40/50\n",
            "23403/23403 [==============================] - 446s 19ms/step - loss: 2.5995e-04 - accuracy: 0.9998 - val_loss: 3.5827e-04 - val_accuracy: 0.9998 - lr: 7.4784e-05\n",
            "Epoch 41/50\n",
            "23403/23403 [==============================] - 447s 19ms/step - loss: 2.4458e-04 - accuracy: 0.9998 - val_loss: 3.6944e-04 - val_accuracy: 0.9998 - lr: 6.7668e-05\n",
            "Epoch 42/50\n",
            "23403/23403 [==============================] - 447s 19ms/step - loss: 2.3217e-04 - accuracy: 0.9998 - val_loss: 3.5540e-04 - val_accuracy: 0.9998 - lr: 6.1228e-05\n",
            "Epoch 43/50\n",
            "23403/23403 [==============================] - 447s 19ms/step - loss: 2.2416e-04 - accuracy: 0.9998 - val_loss: 3.4667e-04 - val_accuracy: 0.9998 - lr: 5.5402e-05\n",
            "Epoch 44/50\n",
            "23403/23403 [==============================] - 447s 19ms/step - loss: 2.1360e-04 - accuracy: 0.9998 - val_loss: 3.5422e-04 - val_accuracy: 0.9998 - lr: 5.0129e-05\n",
            "Epoch 45/50\n",
            "23403/23403 [==============================] - 447s 19ms/step - loss: 2.0756e-04 - accuracy: 0.9998 - val_loss: 3.3646e-04 - val_accuracy: 0.9998 - lr: 4.5359e-05\n",
            "Epoch 46/50\n",
            "23403/23403 [==============================] - 447s 19ms/step - loss: 2.0087e-04 - accuracy: 0.9998 - val_loss: 3.4074e-04 - val_accuracy: 0.9998 - lr: 4.1042e-05\n",
            "Epoch 47/50\n",
            "23403/23403 [==============================] - 447s 19ms/step - loss: 1.9711e-04 - accuracy: 0.9998 - val_loss: 3.4154e-04 - val_accuracy: 0.9998 - lr: 3.7137e-05\n",
            "Epoch 48/50\n",
            "23403/23403 [==============================] - 447s 19ms/step - loss: 1.9241e-04 - accuracy: 0.9998 - val_loss: 3.6180e-04 - val_accuracy: 0.9997 - lr: 3.3603e-05\n",
            "Epoch 49/50\n",
            "23403/23403 [==============================] - 447s 19ms/step - loss: 1.8947e-04 - accuracy: 0.9998 - val_loss: 3.4738e-04 - val_accuracy: 0.9997 - lr: 3.0405e-05\n",
            "Epoch 50/50\n",
            "23403/23403 [==============================] - 446s 19ms/step - loss: 1.8609e-04 - accuracy: 0.9998 - val_loss: 3.4346e-04 - val_accuracy: 0.9997 - lr: 2.7512e-05\n"
          ]
        }
      ],
      "source": [
        "epochs = 50  # This should be at least 30 for convergence\n",
        "lr_schedule = tf.keras.callbacks.LearningRateScheduler(create_lr_func(0.0005, 20, 4.0))\n",
        "checkpoint = keras.callbacks.ModelCheckpoint(\n",
        "    \"models/2022-10-04-Transformer_3to2\", save_best_only=True, monitor=\"val_loss\", save_weights_only=True\n",
        ")\n",
        "\n",
        "callbacks = [lr_schedule, checkpoint]\n",
        "\n",
        "transformer.summary()\n",
        "transformer.compile(\n",
        "    \"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        ")\n",
        "history = transformer.fit(train_ds, epochs=epochs, validation_data=val_ds,\n",
        "                          callbacks = callbacks)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vOOTEZLvO5rw"
      },
      "outputs": [],
      "source": [
        "transformer.save_weights(\"models/2022-10-04-Transformer_3to2_50epochs\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "cSZ7Y7kuO5rw",
        "outputId": "764a420c-4b55-42c2-f73d-2717abf388cd"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAZRElEQVR4nO3dfZAV9Z3v8feXeXB4lodZIgwIVkiuBHkYBnzIBolZVuJVQbOuUtEIUSkrS8pUEi3Nk17jVtxYWfNwuUnmZhFcl6CrMZdKiKxELcwGIgMOIqCGRbwM4cbhQdDAADPzvX/0OUzPYYY5M3PONOc3n1fVr/rxdH97OHxOn+4+3ebuiIhI4euTdAEiIpIbCnQRkUAo0EVEAqFAFxEJhAJdRCQQxUmtePjw4T527NikVi8iUpA2bdq0393L25qWWKCPHTuWmpqapFYvIlKQzOyd9qbpkIuISCAU6CIigVCgi4gEQoEuIhIIBbqISCA6DHQzW2pm75rZ6+1MNzP7oZntNLPXzKwy92WKiEhHstlDXwbMOcP0TwPjU20R8OPulyUiIp3V4XXo7r7OzMaeYZa5wOMe3Yd3g5mda2bnufu+HNUoAWhshOPHo3biRDR88mTrbmZ/vDU3R829pRvvb6/bXoO2+9sbTo/L7M98TXvzdbc/7kx3vM7m9dksK5d31c7Vss7WO313pa5rroHp03NfSy5+WDQK2BMbrkuNOy3QzWwR0V48Y8aMycGqc6u5GRoa4NixqHvyZOuWDqLGRmhqilq6Px46TU2tu20FUPxNYNa69ekDJSVRKy1t6S8paR006WWll1FUFL023YqKWuqIt+bmlvCMt8bGaBvTwdvQ0NLfmRZfRro1NyfzbyrSE8w6N//IkWdvoGfN3auBaoCqqqq8f966w86d8Mor8Kc/wf79cOBA1E33HzkSBXg6xKW1khI455y2W1lZ1B0wAIYObT2ttLT918U/oEpKoLg46hYVtR6XbkVFUUt/2GV++KXHxadlztdWg7b72xtOj8vsz3xNe/N1tz/uTAGSzeuzWVZnQ6or65DcykWg7wVGx4YrUuN63OHDUXhv2NDSDh5smV5aCsOHR23YMJg4EQYPhr59o9avX0t/WdnpwVNa2jpkMrvxPeTMveX2QqatQwFNTad/M0j3txdY6W8C8W8JTU0ttcRbnz4tIZoZrJlB3EfXQYkUjFwE+ipgsZmtBC4GDidx/Py11+DSS+Ho0Wh4wgS47jq45BK4+GIYNw7699eegoiEq8NAN7OfA7OA4WZWB9wPlAC4+0+A1cBVwE7gKLAwX8WeyY9/HO3hPvdcFODnnptEFSIiycnmKpf5HUx34B9yVlEXNDTAypVw/fVw5ZVJViIikpwgjpCuWgXvvQe33pp0JSIiyQki0Jctg4oKuOKKpCsREUlOwQf6vn2wZg3cckt0BYeISG9V8IH+xBPRZXo63CIivV1BB7o7LF8eXa740Y8mXY2ISLIKOtA3bYJt27R3LiICBR7oy5dHv2a88cakKxERSV7BBvrx47BiBcybpx8RiYhAAQf6r34V3adlwYKkKxEROTsUbKAvXx7dgnL27KQrERE5OxRkoP/5z7B6Ndx8s649FxFJK8hAX7EiujWsrm4REWlRkIG+bFn0tI8JE5KuRETk7FFwgV5bG937XCdDRURaK7hA/+Uvo6fq3HRT0pWIiJxdCi7Q778/2ksfOjTpSkREzi4FF+hmcOGFSVchInL2KbhAFxGRtinQRUQCoUAXEQmEAl1EJBAKdBGRQCjQRUQCoUAXEQmEAl1EJBAKdBGRQCjQRUQCoUAXEQmEAl1EJBAKdBGRQCjQRUQCkVWgm9kcM3vTzHaa2b1tTB9jZi+a2atm9pqZXZX7UkVE5Ew6DHQzKwKWAJ8GJgDzzSzzaZ7fAJ5y96nATcD/ynWhIiJyZtnsoc8Adrr7Lnc/AawE5mbM48CgVP9g4E+5K1FERLKRTaCPAvbEhutS4+IeAG42szpgNfDFthZkZovMrMbMaurr67tQroiItCdXJ0XnA8vcvQK4CvhXMztt2e5e7e5V7l5VXl6eo1WLiAhkF+h7gdGx4YrUuLjbgKcA3H09UAYMz0WBIiKSnWwCfSMw3szGmVkp0UnPVRnz/F/gUwBmdiFRoOuYiohID+ow0N29EVgMrAF2EF3Nss3MHjSza1OzfQW4w8y2AD8HFri756toERE5XXE2M7n7aqKTnfFx34r1bwc+ntvSRESkM/RLURGRQCjQRUQCoUAXEQmEAl1EJBAKdBGRQCjQRUQCoUAXEQmEAl1EJBAKdBGRQCjQRUQCoUAXEQmEAl1EJBAKdBGRQCjQRUQCoUAXEQmEAl1EJBAKdBGRQCjQRUQCoUAXEQmEAl1EJBAKdBGRQCjQRUQCoUAXEQmEAl1EJBAKdBGRQCjQRUQCoUAXEQmEAl1EJBAKdBGRQCjQRUQCkVWgm9kcM3vTzHaa2b3tzPP3ZrbdzLaZ2YrclikiIh0p7mgGMysClgCzgTpgo5mtcvftsXnGA/cBH3f3Q2b2V/kqWERE2pbNHvoMYKe773L3E8BKYG7GPHcAS9z9EIC7v5vbMkVEpCPZBPooYE9suC41Lu4jwEfM7D/NbIOZzWlrQWa2yMxqzKymvr6+axWLiEibcnVStBgYD8wC5gP/28zOzZzJ3avdvcrdq8rLy3O0ahERgewCfS8wOjZckRoXVwescveT7v428BZRwIuISA/JJtA3AuPNbJyZlQI3Aasy5vkl0d45Zjac6BDMrhzWKSIiHejwKhd3bzSzxcAaoAhY6u7bzOxBoMbdV6Wm/a2ZbQeagLvd/UA+CxeRs9vJkyepq6ujoaEh6VIKUllZGRUVFZSUlGT9GnP3PJbUvqqqKq+pqUlk3SKSf2+//TYDBw5k2LBhmFnS5RQUd+fAgQO8//77jBs3rtU0M9vk7lVtvU6/FBWRvGhoaFCYd5GZMWzYsE5/u1Ggi0jeKMy7rit/OwW6iARrwIABSZfQoxToIiKBUKCLSPDcnbvvvpuJEydy0UUX8eSTTwKwb98+Zs6cyZQpU5g4cSIvv/wyTU1NLFiw4NS8jz76aMLVZ6/DyxZFRLrtS1+C2trcLnPKFPj+97Oa9Re/+AW1tbVs2bKF/fv3M336dGbOnMmKFSu48sor+frXv05TUxNHjx6ltraWvXv38vrrrwPw3nvv5bbuPNIeuogE73e/+x3z58+nqKiIESNGcPnll7Nx40amT5/OY489xgMPPMDWrVsZOHAgF1xwAbt27eKLX/wizz33HIMGDUq6/KxpD11E8i/LPemeNnPmTNatW8evf/1rFixYwJe//GU+97nPsWXLFtasWcNPfvITnnrqKZYuXZp0qVnRHrqIBO8Tn/gETz75JE1NTdTX17Nu3TpmzJjBO++8w4gRI7jjjju4/fbb2bx5M/v376e5uZnPfOYzPPTQQ2zevDnp8rOmPXQRCd51113H+vXrmTx5MmbGd7/7XT70oQ+xfPlyHnnkEUpKShgwYACPP/44e/fuZeHChTQ3NwPwne98J+Hqs6ef/otIXuzYsYMLL7ww6TIKWlt/Q/30X0SkF1Cgi4gEQoEuIhIIBbqISCAU6CIigVCgi4gEQoEuIhIIBbqISDc0NjYmXcIpCnQRCda8efOYNm0aH/vYx6iurgbgueeeo7KyksmTJ/OpT30KgA8++ICFCxdy0UUXMWnSJJ555hmg9QMynn76aRYsWADAggULuPPOO7n44ou55557eOWVV7j00kuZOnUql112GW+++SYATU1NfPWrX2XixIlMmjSJH/3oR7zwwgvMmzfv1HKff/55rrvuupxsr376LyJ5l9Tdc5cuXcrQoUM5duwY06dPZ+7cudxxxx2sW7eOcePGcfDgQQC+/e1vM3jwYLZu3QrAoUOHOlx/XV0dv//97ykqKuLIkSO8/PLLFBcXs3btWr72ta/xzDPPUF1dze7du6mtraW4uJiDBw8yZMgQvvCFL1BfX095eTmPPfYYn//857v99wAFuogE7Ic//CHPPvssAHv27KG6upqZM2cybtw4AIYOHQrA2rVrWbly5anXDRkypMNl33DDDRQVFQFw+PBhbr31Vv74xz9iZpw8efLUcu+8806Ki4tbre+WW27hiSeeYOHChaxfv57HH388J9urQBeRvEvi7rkvvfQSa9euZf369fTr149Zs2YxZcoU3njjjayXEX9Qc0NDQ6tp/fv3P9X/zW9+k09+8pM8++yz7N69m1mzZp1xuQsXLuSaa66hrKyMG2644VTgd5eOoYtIkA4fPsyQIUPo168fb7zxBhs2bKChoYF169bx9ttvA5w65DJ79myWLFly6rXpQy4jRoxgx44dNDc3n9rTb29do0aNAmDZsmWnxs+ePZuf/vSnp06cptc3cuRIRo4cyUMPPcTChQtzts0KdBEJ0pw5c2hsbOTCCy/k3nvv5ZJLLqG8vJzq6mquv/56Jk+ezI033gjAN77xDQ4dOsTEiROZPHkyL774IgAPP/wwV199NZdddhnnnXdeu+u65557uO+++5g6dWqrq15uv/12xowZw6RJk5g8eTIrVqw4Ne2zn/0so0ePzukdKXX7XBHJC90+98wWL17M1KlTue2229qdp7O3z9UxdBGRHjZt2jT69+/P9773vZwuV4EuItLDNm3alJfl6hi6iEggFOgikjdJnaMLQVf+dgp0EcmLsrIyDhw4oFDvAnfnwIEDlJWVdep1WR1DN7M5wA+AIuBn7v5wO/N9BngamO7uuoRFpBerqKigrq6O+vr6pEspSGVlZVRUVHTqNR0GupkVAUuA2UAdsNHMVrn79oz5BgJ3AX/oVAUiEqSSkpJTP7GXnpHNIZcZwE533+XuJ4CVwNw25vs28E9AQxvTREQkz7IJ9FHAnthwXWrcKWZWCYx291+faUFmtsjMasysRl/DRERyq9snRc2sD/DPwFc6mtfdq929yt2rysvLu7tqERGJySbQ9wKjY8MVqXFpA4GJwEtmthu4BFhlZm3+NFVERPIjm0DfCIw3s3FmVgrcBKxKT3T3w+4+3N3HuvtYYANwra5yERHpWR0Gurs3AouBNcAO4Cl332ZmD5rZtfkuUEREspPVdejuvhpYnTHuW+3MO6v7ZYmISGfpl6IiIoFQoIuIBEKBLiISCAW6iEggFOgiIoFQoIuIBEKBLiISCAW6iEggFOgiIoFQoIuIBEKBLiISCAW6iEggFOgiIoFQoIuIBEKBLiISCAW6iEggFOgiIoFQoIuIBEKBLiISCAW6iEggFOgiIoFQoIuIBEKBLiISCAW6iEggFOgiIoFQoIuIBEKBLiISCAW6iEggFOgiIoFQoIuIBCKrQDezOWb2ppntNLN725j+ZTPbbmavmdlvzez83JcqIiJn0mGgm1kRsAT4NDABmG9mEzJmexWocvdJwNPAd3NdqIiInFk2e+gzgJ3uvsvdTwArgbnxGdz9RXc/mhrcAFTktkwREelINoE+CtgTG65LjWvPbcBv2ppgZovMrMbMaurr67OvMm7vXli1qmuvFREJWE5PiprZzUAV8Ehb09292t2r3L2qvLy8ayt54gmYOxcOHep6oSIiAcom0PcCo2PDFalxrZjZ3wBfB6519+O5Ka8NlZVR99VX87YKEZFClE2gbwTGm9k4MysFbgJaHfMws6nAT4nC/N3clxmTDvTNm/O6GhGRQtNhoLt7I7AYWAPsAJ5y921m9qCZXZua7RFgAPDvZlZrZvk7yD1sGJx/PmzalLdViIgUouJsZnL31cDqjHHfivX/TY7rOrPKSu2hi4hkKMxfik6bBm+9BUeOJF2JiMhZozADPX0cvbY22TpERM4ihR3oOo4uInJKYQb6iBEwapSOo4uIxBRmoINOjIqIZCjcQJ82Dd54A/7yl6QrERE5KxRuoFdWQnMzbNmSdCUiImeFwg500IlREZGUwg30kSOjk6M6ji4iAhRyoJtFe+naQxcRAQo50CE6Mbp9Oxw7lnQlIiKJK+xAr6yEpibYujXpSkREElf4gQ467CIiQqEH+pgx0e10dWJURKTAA10nRkVETinsQIfoxOjrr8Px/D31TkSkEBR+oFdWwsmTsG1b0pWIiCQqjEAHHXYRkV6v8AP9ggtg8GCdGBWRXq/wA10nRkVEgBACHaITo6+9Fh1LFxHppcII9MrK6CqX7duTrkREJDHhBDroOLqI9GphBPr48TBggAJdRHq1MAK9Tx+YOlUnRkWkVwsj0CE6MVpbG919UUSkFwon0Csro/uiL1mi+6OLSK8UTqBfdRVMmQJ33QUVFXD33bBrV9JViYj0mHACPX0b3ZdegiuugEcfhQ9/GK6+Gn7zG2hoSLpCEZG8Kk66gJwyg8svj1pdHVRXR+2qq6Jp558PH/0ofOQjLd3Ro2Ho0KgVh/XnEJHexdw9kRVXVVV5TU1N/ld04gSsXg1btsCbb0btrbfggw9On3fQoJZwHzwY+veHfv1at7594ZxzolZa2tJ/zjlQUhJ9KJSUtG5FRdGVOH36tO4HcI9ac3NLt7ER/vIXOHo06qb7GxqiD6aiopblpPsbG6NfyqZberioqKXOeLdv32h7+vdv2c50/+DBUFaW/38bEek0M9vk7lVtTctql9TM5gA/AIqAn7n7wxnTzwEeB6YBB4Ab3X13d4rOmdJSmDcvamnusG9fFO779sHBg63bgQNw+HDUjh49vRUKs2hbu6K0NAr2QYOibrxljhs06PQ2cGDUSkpyu00i0q4OA93MioAlwGygDthoZqvcPf47+9uAQ+7+YTO7Cfgn4MZ8FJwTZjByZNQ6yz3a8z1+PNr7P368pcX3jOOtuTm6nLK5uaWlL680i/a0493i4tP3mvv1i/aa3VuW1dTU0l9UdPo3gz59ovnTdca7x461fAOIdz/4oOXDLLPt3AlHjkT9R45k92HRt29LwKfDfsCAlm878W8+8VZW1tItK4v+JulvI5nfTtKtrXnaaum/debfPd1Nt8xhkbNcNnvoM4Cd7r4LwMxWAnOBeKDPBR5I9T8N/E8zM0/qeE4+mUV7r6WlSVeSHbOWQ0K51NwcfQikw/3996Nuuh0+HI3LHH/kCOzd2/KBEu82N+e2xnyIB3xnW/z1bfV31G2rPz5PW8Od7W9vOdmMz+WyuvIB2tnXJPkhff/9cGPu93mzCfRRwJ7YcB1wcXvzuHujmR0GhgH74zOZ2SJgEcCYMWO6WLKcFfr0aTmskgvpbxINDVG4HzvW0t/QEH3zSX8jyfyGkm7xeeLfhjK/GcXPW8TPXcS7mec2utvS29hef0fdtvrj87Q13Nn+9paTzfhcLqsr+4GdfU3S+5pDhuRlsT16WYe7VwPVEJ0U7cl1y1ku/k1i8OCkqxEpSNlch74XGB0brkiNa3MeMysGBhOdHBURkR6STaBvBMab2TgzKwVuAlZlzLMKuDXV/3fAC0EePxcROYt1eMgldUx8MbCG6LLFpe6+zcweBGrcfRXwL8C/mtlO4CBR6IuISA/K6hi6u68GVmeM+1asvwG4IbeliYhIZ4RzLxcRkV5OgS4iEggFuohIIBToIiKBSOxui2ZWD7zTxZcPJ+NXqL1Eb91u6L3bru3uXbLZ7vPdvbytCYkFeneYWU17t48MWW/dbui9267t7l26u9065CIiEggFuohIIAo10KuTLiAhvXW7ofduu7a7d+nWdhfkMXQRETldoe6hi4hIBgW6iEggCi7QzWyOmb1pZjvN7N6k68kXM1tqZu+a2euxcUPN7Hkz+2Oqm5/HniTIzEab2Ytmtt3MtpnZXanxQW+7mZWZ2StmtiW13f8jNX6cmf0h9X5/MnUL6+CYWZGZvWpmv0oNB7/dZrbbzLaaWa2Z1aTGdet9XlCBHntg9aeBCcB8M5uQbFV5swyYkzHuXuC37j4e+G1qODSNwFfcfQJwCfAPqX/j0Lf9OHCFu08GpgBzzOwSogeuP+ruHwYOET2QPUR3ATtiw71luz/p7lNi1553631eUIFO7IHV7n4CSD+wOjjuvo7o3vJxc4Hlqf7lwLweLaoHuPs+d9+c6n+f6D/5KALfdo98kBosSTUHriB68DoEuN0AZlYB/HfgZ6lhoxdsdzu69T4vtEBv64HVoxKqJQkj3H1fqv//ASOSLCbfzGwsMBX4A71g21OHHWqBd4Hngf8C3nP3xtQsob7fvw/cAzSnhofRO7bbgf8ws01mtig1rlvv8x59SLTkjru7mQV7zamZDQCeAb7k7keinbZIqNvu7k3AFDM7F3gW+G8Jl5R3ZnY18K67bzKzWUnX08P+2t33mtlfAc+b2RvxiV15nxfaHno2D6wO2Z/N7DyAVPfdhOvJCzMrIQrzf3P3X6RG94ptB3D394AXgUuBc1MPXocw3+8fB641s91Eh1CvAH5A+NuNu+9Ndd8l+gCfQTff54UW6Nk8sDpk8Ydx3wr8nwRryYvU8dN/AXa4+z/HJgW97WZWntozx8z6ArOJzh+8SPTgdQhwu939PnevcPexRP+fX3D3zxL4dptZfzMbmO4H/hZ4nW6+zwvul6JmdhXRMbf0A6v/MeGS8sLMfg7MIrqd5p+B+4FfAk8BY4huPfz37p554rSgmdlfAy8DW2k5pvo1ouPowW67mU0iOglWRLSj9ZS7P2hmFxDtuQ4FXgVudvfjyVWaP6lDLl9196tD3+7U9j2bGiwGVrj7P5rZMLrxPi+4QBcRkbYV2iEXERFphwJdRCQQCnQRkUAo0EVEAqFAFxEJhAJdRCQQCnQRkUD8fxBXH98jyHp+AAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(history.history['loss'], c=\"r\", label=\"loss\")\n",
        "plt.plot(history.history['accuracy'], c='b', label=\"accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transformer.load_weights(\"models/2022-10-04-Transformer_3to2_50epochs\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGOjJzjh9mCv",
        "outputId": "b7c3477a-f94e-49d1-a46c-42be8b762c58"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fd5ff73b1d0>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_vocab = y_vectorization.get_vocabulary()\n",
        "y_index_lookup = dict(zip(range(len(y_vocab)), y_vocab))\n",
        "max_decoded_sentence_length = 350\n",
        "\n",
        "\n",
        "def decode_sequence(input_sentence):\n",
        "    tokenized_input_sentence = X_vectorization([input_sentence])\n",
        "    decoded_sentence = \"[start]\"\n",
        "    probas = []\n",
        "    for i in range(max_decoded_sentence_length):\n",
        "        tokenized_target_sentence = y_vectorization([decoded_sentence])[:, :-1]\n",
        "        predictions = transformer([tokenized_input_sentence, tokenized_target_sentence])\n",
        "\n",
        "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
        "        # proba = proba*predictions[0,i,sampled_token_index]\n",
        "        probas = probas + predictions[0,i,sampled_token_index]\n",
        "        sampled_token = y_index_lookup[sampled_token_index]\n",
        "        decoded_sentence += \" \" + sampled_token\n",
        "\n",
        "        if sampled_token == \"[END]\":\n",
        "            break\n",
        "    return decoded_sentence, probas.numpy()"
      ],
      "metadata": {
        "id": "sF91ZSzaoIwe"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decode_sequence(X_val_text[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySfCsBaD-HsU",
        "outputId": "2c060686-997c-4c21-882f-2c7a5c900c50"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('[start] mul( mul s- 16 pow 81 s- 1 pow e 6 pow add( reg_prop s_33 mul 2 s_23 ) s- 2 pow add( m2mu reg_prop s_11 mul s- 2 s_14 ) s- 2 add( mul m2d add( mul s- 2 m2muxs_25 mul s- 2 m2muxs_35 mul 4 m2muxs_23 mul 4 m2muxs_33 mul( s- 2 s_14 s_23 ) mul( s- 2 s_14 s_33 ) mul( 2 s_12 s_45 ) mul( 2 s_13 s_45 ) mul( 2 s_15 s_24 ) mul( 2 s_15 s_34 ) ) mul m4d add mul s- 2 s_14 mul 4 m2mu mul( s- 1 m2muxs_25 s_33 ) mul( 2 m2muxs_23 s_35 ) mul( s_12 s_33 s_45 ) mul( s_15 s_24 s_33 ) mul( s- 2 s_13 s_23 s_45 ) mul( s- 2 s_15 s_23 s_34 ) ) ) [END]',\n",
              " array([], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_true_file = \"./predictions/2022-10-07-train_true.txt\"\n",
        "train_pred_file = \"./predictions/2022-10-07-train_pred.txt\"\n",
        "train_pred_probas_file =  \"./predictions/2022-10-07-train_pred_probas.txt\"\n",
        "val_true_file = \"./predictions/2022-10-07-val_true.txt\"\n",
        "val_pred_file = \"./predictions/2022-10-07-val_pred.txt\"\n",
        "val_pred_probas_file =  \"./predictions/2022-10-07-val_pred_probas.txt\""
      ],
      "metadata": {
        "id": "J7vEfzhc-MvG"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAJHs9ZuRNnf",
        "outputId": "fc432ce3-afe0-4a01-e199-1904198e6861"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['2022-07-20-RNNAttention',\n",
              " '2022-07-20-FirstTransformer',\n",
              " 'data.nosync_old',\n",
              " 'data.nosync',\n",
              " '2022-08-22-Transformer',\n",
              " 'models',\n",
              " '2022-08-24-Transformer-NewData',\n",
              " 'QED',\n",
              " 'predictions']"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_val_pred = [decode_sequence(x) for x in tqdm(X_val_text[0:500])]\n",
        "y_val_probas = [y[1] for y in y_val_pred]\n",
        "y_val_pred = [y[0] for y in y_val_pred]\n",
        "\n",
        "with open(val_pred_file, \"w\") as f:\n",
        "    for line in y_val_pred:\n",
        "        f.write(line)\n",
        "        f.write(\"\\n\")\n",
        "\n",
        "with open(val_true_file, \"w\") as f:\n",
        "    for line in y_val_text:\n",
        "        f.write(line)\n",
        "        f.write(\"\\n\")\n",
        "\n",
        "with open(val_pred_probas_file, \"w\") as f:\n",
        "    for line in y_val_probas:\n",
        "        f.write(str(line))\n",
        "        f.write(\"\\n\")"
      ],
      "metadata": {
        "id": "WflbdJbu-25f"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def token_accuracy(y_true, y_pred, verbose=0, pred_has_start_end_tokens=True):\n",
        "    \"\"\"\n",
        "    compare two arrays and check how many entries are the same at the same position\n",
        "    \"\"\"\n",
        "    true = y_true.split(\" \")\n",
        "    pred = y_pred.split(\" \")\n",
        "    if pred_has_start_end_tokens:\n",
        "        pred = pred[1:-1]\n",
        "    max_ind = np.min([len(true), len(pred)])\n",
        "    correct_ctr = 0\n",
        "    # ignore [start] and [end]\n",
        "    max_correct = len(pred)\n",
        "    for i in range(max_ind):\n",
        "        if verbose: ic([true[i], pred[i]])\n",
        "        if true[i] == pred[i]:\n",
        "            correct_ctr += 1\n",
        "    return correct_ctr / max_correct"
      ],
      "metadata": {
        "id": "W_OeJ6UDSUEd"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_accs = [token_accuracy(y_val_text[i], y_val_pred[i], pred_has_start_end_tokens=False) for i in range(len(y_val_pred))]\n",
        "print(\"val:\", np.mean(val_accs)) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MsNwC6ku_REv",
        "outputId": "ef687941-b971-4bfe-bdeb-5bb5dd580805"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val: 0.4816969419028278\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_pred = [decode_sequence(x) for x in tqdm(X_train_text[0:100])]\n",
        "y_train_probas = [y[1] for y in y_train_pred]\n",
        "y_train_pred = [y[0] for y in y_train_pred]\n",
        "\n",
        "with open(train_true_file, \"w\") as f:\n",
        "    for line in y_train_text:\n",
        "        f.write(line)\n",
        "        f.write(\"\\n\")\n",
        "\n",
        "with open(train_pred_file, \"w\") as f:\n",
        "    for line in y_train_pred:\n",
        "        f.write(line)\n",
        "        f.write(\"\\n\")\n",
        "\n",
        "with open(train_pred_probas_file, \"w\") as f:\n",
        "    for line in y_train_probas:\n",
        "        f.write(str(line))\n",
        "        f.write(\"\\n\")"
      ],
      "metadata": {
        "id": "b9oaUUAg-T6K"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "symba",
      "language": "python",
      "name": "symba"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "c4adc2ea131058d4ca334736eaf83f8a99f586a60b7e02773f5921bb39d3dbeb"
      }
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}